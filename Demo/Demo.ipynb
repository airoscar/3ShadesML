{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optionally if using AMD/Intel GPU with PlaidML\n",
    "# import os\n",
    "# os.environ['KERAS_BACKEND']='plaidml.keras.backend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import urllib.request\n",
    "import time\n",
    "# %matplotlib inline\n",
    "cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "model = load_model('../CNNPredictions/CNN-final-model-v3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(img):\n",
    "    plt.imshow(img)\n",
    "#     plt.show()    # display imageinline\n",
    "    cv2.imwrite( \"output.jpg\", img )\n",
    "    ! open output.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def processImage(img):\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    crop_margin = 0.2\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cascade.detectMultiScale(gray_img, scaleFactor=1.3, minNeighbors=5)\n",
    "    person_num = 0\n",
    "    for (x,y,w,h) in faces:\n",
    "        person_num += 1\n",
    "\n",
    "        x1 = int(x - crop_margin * w)\n",
    "        y1 = int(y - crop_margin * h)\n",
    "        x2 = int(x + (1 + crop_margin) * w)\n",
    "        y2 = int(y + (1 + crop_margin) * h)\n",
    "\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        if x2 > width:\n",
    "            x2 = width\n",
    "        if y2 > height:\n",
    "            y2 = height\n",
    "\n",
    "\n",
    "        crop_img = gray_img[y1:y2, x1:x2]\n",
    "        try: \n",
    "    #         print(f'Processing face #{person_num}: ({x1},{y1}),({x2},{y2})')\n",
    "            resized_normalized = cv2.resize(crop_img, (100, 100))/255\n",
    "            cv2.rectangle(img, (x1,y1), (x2, y2), (255,255,0), 2)\n",
    "            for_predict = resized_normalized.reshape(-1,100,100,1)\n",
    "            start = time.time()\n",
    "            prediction = model.predict(for_predict)[0][0]\n",
    "            end = time.time()\n",
    "            print(f\"Inference: {end-start} seconds\")\n",
    "\n",
    "            if (prediction >= 0.5):\n",
    "                text = f'M({prediction:.2f})'\n",
    "                cv2.putText(img, text, (x,y), font, w/140, (255,200,0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                text = f'F({prediction:.2f})'\n",
    "                cv2.putText(img, text, (x,y), font, w/140, (150,150,255), 2, cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "        except:\n",
    "    #         print(f'Image({width},{height}) failed to crop face #{person_num}: ({x1},{y1}),({x2},{y2})')\n",
    "            pass\n",
    "    showImg(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading from file \n",
    "img = cv2.imread('group.jpg')\n",
    "processImage(img)\n",
    "showImg(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guess the gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from url \n",
    "resp = urllib.request.urlopen('https://preview.redd.it/6wxvhszskbn21.jpg?width=640&crop=smart&auto=webp&s=0b6830f71ff094fd70616b64165b7c788f386764')\n",
    "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "img = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "showImg(img)\n",
    "input()\n",
    "processImage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from url\n",
    "resp = urllib.request.urlopen('https://i.redd.it/wn3w5zlkf1e21.jpg')\n",
    "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "img = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "showImg(img)\n",
    "input()\n",
    "processImage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading from url\n",
    "resp = urllib.request.urlopen('https://i.redd.it/w8cto4248ta21.png')\n",
    "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "img = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "showImg(img)\n",
    "input()\n",
    "processImage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading from url\n",
    "resp = urllib.request.urlopen('https://preview.redd.it/lgs5bt0ylaa21.jpg?width=640&crop=smart&auto=webp&s=bbd54f6ae61a76a270db0500568038973ee6dabc')\n",
    "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "img = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "showImg(img)\n",
    "input()\n",
    "processImage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from url\n",
    "resp = urllib.request.urlopen('https://preview.redd.it/d6e2j5vgs1j21.jpg?width=960&crop=smart&auto=webp&s=bb4164e96f6436be2d29ce38099c5f7a0cd1ddeb')\n",
    "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "img = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "showImg(img)\n",
    "input()\n",
    "processImage(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with video feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # Camera device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "img = cv2.imread('group.jpg')\n",
    "crop_margin = 0.2\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cascade.detectMultiScale(gray_img, scaleFactor=1.3, minNeighbors=5)\n",
    "    person_num = 0\n",
    "    for (x,y,w,h) in faces:\n",
    "        person_num += 1\n",
    "\n",
    "        x1 = int(x - crop_margin * w)\n",
    "        y1 = int(y - crop_margin * h)\n",
    "        x2 = int(x + (1 + crop_margin) * w)\n",
    "        y2 = int(y + (1 + crop_margin) * h)\n",
    "\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        if x2 > width:\n",
    "            x2 = width\n",
    "        if y2 > height:\n",
    "            y2 = height\n",
    "\n",
    "\n",
    "        crop_img = gray_img[y1:y2, x1:x2]\n",
    "        try: \n",
    "    #         print(f'Processing face #{person_num}: ({x1},{y1}),({x2},{y2})')\n",
    "            resized_normalized = cv2.resize(crop_img, (100, 100))/255\n",
    "            cv2.rectangle(img, (x1,y1), (x2, y2), (255,255,0), 2)\n",
    "            prediction = model.predict(resized_normalized.reshape(-1,100,100,1))[0][0]\n",
    "\n",
    "            if (prediction >= 0.5):\n",
    "                text = f'M({prediction:.2f})'\n",
    "            else:\n",
    "                text = f'F({prediction:.2f})'\n",
    "\n",
    "            cv2.putText(img, text, (x,y), font, w/140, (255,255,0), 2, cv2.LINE_AA)\n",
    "        except:\n",
    "    #         print(f'Image({width},{height}) failed to crop face #{person_num}: ({x1},{y1}),({x2},{y2})')\n",
    "            pass\n",
    "    \n",
    "    cv2.imshow('img', img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: There seems to be a bug with OpenCV running in Jupyter Notebook, cv2.imshow() causes the program to hang. The last line 'cv2.waitKey(1)' somehow bypasses it and allows the cv2.imshow() to work. Even so, you still need to restart the kernel after stopping the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reboot kernel\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
