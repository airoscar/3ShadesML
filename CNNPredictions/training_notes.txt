BN-3-conv-32-node-2-dens-1553635516: started training with BN and dropout added in hidden layers.

BN-3-conv-32-node-2-dens-1553636464: same settings as 1553635516 but using a larger dataset to compare difference in results (1_pct vs 5_pct datasets). Overall increased accuracy and reduced loss.

BN-3-conv-32-node-2-dens-1553641383: same setting as 1553636464 but using large dense layers to compare difference in results (2048 nodes vs 1024 nodes). accuracy dropped, loss increased. Going back to 8X dense layer size.

BN-4-conv-32-node-2-dens-1553646613: same setting as 1553636464 but using an extra set of hidden layers: slightly improved val accuracy and loss.

BN-4-conv-32-node-2-dens-1553651832: same setting as 1553646613 but using larger image size (224px vs 120px).slightly improved accuracy and loss. But training takes twice as long. Going back to 120px images for now, we can come back to 224px images when we have everything else finalized.

BN-5-conv-32-node-2-dens-1553695243: same setting as 1553646613 but added another set of hidden layers. No noticeable change in loss, small improvement in val accuracy.

BN-5-conv-32-node-3-dens-1553703610: same setting as 1553695243 but added another set of dense layers. Validation accuracy and loss are slightly worse. Going back to previous settings.

So far, the best trials are BN-5-conv-32-node-2-dens-1553695243 and BN-4-conv-32-node-2-dens-1553646613. The only difference between these two are the number of hidden layers. We want to see if the two networks will start to differentiate with larger dataset. The next two trials will be using 10pct data set on these two networks for comparison.

BN-4-conv-32-node-2-dens-1553710479: same as BN-4-conv-32-node-2-dens-1553646613 but using larger data set (10pct vs 5pct).

BN-5-conv-32-node-2-dens-1553721908: same as BN-5-conv-32-node-2-dens-1553695243 but using larger data set (10pct vs 5pct).
