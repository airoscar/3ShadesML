{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiment Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [5]      # number of conv layers\n",
    "layer_sizes = [32]     # number of nodes in a layer\n",
    "dense_layers = [2]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_all.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196464, 10) (10340, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 100\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "batch_size = 64\n",
    "inputShape = (image_reshape_size, image_reshape_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>pic_date</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162143</th>\n",
       "      <td>58/nm0005158_rm1436916480_1970-11-20_2003.jpg</td>\n",
       "      <td>16965</td>\n",
       "      <td>Sabrina Lloyd</td>\n",
       "      <td>1970-11-20</td>\n",
       "      <td>0</td>\n",
       "      <td>4.224586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>[107.93942350923744, 54.230711754618724, 187.9...</td>\n",
       "      <td>32.115649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129828</th>\n",
       "      <td>07/nm0001807_rm1897044736_1933-12-19_2007.jpg</td>\n",
       "      <td>3752</td>\n",
       "      <td>Cicely Tyson</td>\n",
       "      <td>1933-12-19</td>\n",
       "      <td>0</td>\n",
       "      <td>3.434887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>[78.75376318187809, 59.19832238640856, 166.221...</td>\n",
       "      <td>73.036407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389973</th>\n",
       "      <td>79/nm0272479_rm1974701056_1975-10-22_2009.jpg</td>\n",
       "      <td>9031</td>\n",
       "      <td>Jesse Tyler Ferguson</td>\n",
       "      <td>1975-10-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>[205.814, 123.83, 266.448, 184.464]</td>\n",
       "      <td>33.197122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path     id  \\\n",
       "162143  58/nm0005158_rm1436916480_1970-11-20_2003.jpg  16965   \n",
       "129828  07/nm0001807_rm1897044736_1933-12-19_2007.jpg   3752   \n",
       "389973  79/nm0272479_rm1974701056_1975-10-22_2009.jpg   9031   \n",
       "\n",
       "                        name        dob gender    score1  score2   pic_date  \\\n",
       "162143         Sabrina Lloyd 1970-11-20      0  4.224586     NaN 2003-01-01   \n",
       "129828          Cicely Tyson 1933-12-19      0  3.434887     NaN 2007-01-01   \n",
       "389973  Jesse Tyler Ferguson 1975-10-22      1  0.899851     NaN 2009-01-01   \n",
       "\n",
       "                                                   region        age  \n",
       "162143  [107.93942350923744, 54.230711754618724, 187.9...  32.115649  \n",
       "129828  [78.75376318187809, 59.19832238640856, 166.221...  73.036407  \n",
       "389973                [205.814, 123.83, 266.448, 184.464]  33.197122  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10340 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "# train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "#                                             directory=input_image_root_dir,\n",
    "#                                             x_col=\"path\", y_col=\"gender\",\n",
    "#                                             subset=\"training\",\n",
    "#                                             class_mode=\"binary\",\n",
    "#                                             color_mode=\"grayscale\",\n",
    "#                                             target_size=(image_reshape_size,image_reshape_size),\n",
    "#                                             batch_size=batch_size,\n",
    "#                                             seed=1,\n",
    "#                                             shuffle=True)\n",
    "\n",
    "# val_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "#                                             directory=input_image_root_dir,\n",
    "#                                             x_col=\"path\", y_col=\"gender\",\n",
    "#                                             subset=\"validation\",\n",
    "#                                             class_mode=\"binary\",\n",
    "#                                             color_mode=\"grayscale\",\n",
    "#                                             target_size=(image_reshape_size,image_reshape_size),\n",
    "#                                             batch_size=batch_size,\n",
    "#                                             seed=1,\n",
    "#                                             shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                            directory=input_image_root_dir, \n",
    "                                            x_col=\"path\", y_col=None, \n",
    "                                            class_mode=None, \n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'BN-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            # Make sure the following subfolder exist\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            checkpoint = ModelCheckpoint('weights/{}'.format(NAME), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "            callbacks = [tensorboard, checkpoint]\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\", input_shape=inputShape))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                layer_size *= 2\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.35))   # Started with 0.25, increased to 0.5\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            layer_size *= 4 # to get the dense layer to be 8X of last output size\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Dropout(0.6))    # started with 0.5, increased to 0.7\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            # Optional for resuming, load weights\n",
    "            model.load_weights('weights/BN-5-conv-32-node-2-dens-1554706050')\n",
    "\n",
    "            opt = Adam(lr=0.0005)   # Start with default of 0.001, slow down in subsequent epoch manually if needed\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "            \n",
    "#             model.fit_generator(generator=train_generator,\n",
    "#                                 steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "#                                 callbacks = callbacks,\n",
    "#                                 validation_data=val_generator,\n",
    "#                                 validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "#                                 epochs=15,\n",
    "#                                 use_multiprocessing=False,\n",
    "#                                 workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('CNN-final-model-v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10340/10340 [==============================] - 236s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                            steps=test_generator.n//test_generator.batch_size,\n",
    "                            verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = df_test.gender.astype(int)\n",
    "y_pred = [1 if x>=0.5 else 0 for x in pred]\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3690, 1435],\n",
       "       [ 586, 4629]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm[0][0]\n",
    "TP = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7633575197889182"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876318312559923"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045454545454546"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TP+TN)/(TN+TP+FN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb383b3898>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(cm, annot=True, square=True, cmap='Blues',  fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
