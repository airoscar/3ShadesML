{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'\n",
    "\n",
    "# When using plaidml, the libraries are imported from keras instead of tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [5]      # number of conv layers\n",
    "layer_sizes = [64]  # number of nodes in a layer\n",
    "dense_layers = [3]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_1pct.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4297, 10) (226, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 224\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "batch_size = 64\n",
    "inputShape = (image_reshape_size, image_reshape_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>pic_date</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351096</th>\n",
       "      <td>67/nm0755267_rm3707735808_1980-4-8_2001.jpg</td>\n",
       "      <td>10591</td>\n",
       "      <td>Katee Sackhoff</td>\n",
       "      <td>1980-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>3.704906</td>\n",
       "      <td>3.597096</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>[159.42317678741446, 51.63402111024036, 209.90...</td>\n",
       "      <td>20.734170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436852</th>\n",
       "      <td>25/nm0090225_rm1239005952_1964-10-25_2007.jpg</td>\n",
       "      <td>13481</td>\n",
       "      <td>Michael Boatman</td>\n",
       "      <td>1964-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>2.629246</td>\n",
       "      <td>1.647017</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>[80.61172611750719, 114.87418016786741, 131.33...</td>\n",
       "      <td>42.185671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115652</th>\n",
       "      <td>18/nm0001518_rm2982264064_1961-10-26_2011.jpg</td>\n",
       "      <td>5456</td>\n",
       "      <td>Dylan McDermott</td>\n",
       "      <td>1961-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>2.793912</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>[446.31, 70.47, 570.72, 194.88000000000002]</td>\n",
       "      <td>49.183761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path     id             name  \\\n",
       "351096    67/nm0755267_rm3707735808_1980-4-8_2001.jpg  10591   Katee Sackhoff   \n",
       "436852  25/nm0090225_rm1239005952_1964-10-25_2007.jpg  13481  Michael Boatman   \n",
       "115652  18/nm0001518_rm2982264064_1961-10-26_2011.jpg   5456  Dylan McDermott   \n",
       "\n",
       "              dob gender    score1    score2   pic_date  \\\n",
       "351096 1980-04-08      0  3.704906  3.597096 2001-01-01   \n",
       "436852 1964-10-25      1  2.629246  1.647017 2007-01-01   \n",
       "115652 1961-10-26      1  2.793912  1.419481 2011-01-01   \n",
       "\n",
       "                                                   region        age  \n",
       "351096  [159.42317678741446, 51.63402111024036, 209.90...  20.734170  \n",
       "436852  [80.61172611750719, 114.87418016786741, 131.33...  42.185671  \n",
       "115652        [446.31, 70.47, 570.72, 194.88000000000002]  49.183761  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3868 images belonging to 2 classes.\n",
      "Found 429 images belonging to 2 classes.\n",
      "Found 226 images.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode=\"binary\",\n",
    "#                                             color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode=\"binary\",\n",
    "#                                             color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                            directory=input_image_root_dir, \n",
    "                                            x_col=\"path\", y_col=None, \n",
    "                                            class_mode=None, \n",
    "#                                             color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb-5-conv-64-node-3-dens-1553631248\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 767s 6s/step - loss: 0.7068 - acc: 0.5695 - val_loss: 0.6893 - val_acc: 0.5601\n",
      "Epoch 2/10\n",
      " 32/120 [=======>......................] - ETA: 8:40 - loss: 0.6846 - acc: 0.5678"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'rgb-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            callbacks = [tensorboard]\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(ZeroPadding2D((1,1), input_shape=inputShape))\n",
    "            model.add(Conv2D(layer_size, (3,3), activation=\"relu\"))\n",
    "#             model.add(ZeroPadding2D((1,1)))\n",
    "#             model.add(Conv2D(layer_size, (3, 3), activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                layer_size *= 2\n",
    "                model.add(ZeroPadding2D((1,1)))\n",
    "                model.add(Conv2D(layer_size, (3,3), activation=\"relu\"))\n",
    "#                 model.add(ZeroPadding2D((1,1)))\n",
    "#                 model.add(Conv2D(layer_size, (3, 3), activation='relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "#                 layer_size *= 2\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(Dropout(0.2))\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            opt = Adam(lr=0.001)\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                                callbacks = callbacks,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                                epochs=10,\n",
    "                                use_multiprocessing=False,\n",
    "                                workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Lambda, Conv2D\n",
    "from keras.layers import GlobalAveragePooling2D, Input, Dropout\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import numpy as np\n",
    "import urllib\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "model_path = 'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "target_size=(224, 224)\n",
    "batch_size=32\n",
    "\n",
    "def preprocess_image(im):\n",
    "    vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "    #im = cv2.resize(cv2.imread(path), (224, 224)).astype(np.float32)\n",
    "    im = (im - vgg_mean)\n",
    "    return im[:, ::-1] # RGB to BGR\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(preprocess_image, input_shape=inputShape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=inputShape, activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "model.load_weights(model_path)\n",
    "\n",
    "\n",
    "x = Dense(1, activation='softmax')(model.layers[-2].output)\n",
    "model = Model(model.input, x)\n",
    "\n",
    "for layer in model.layers: \n",
    "    layer.trainable=False\n",
    "\n",
    "opt = Adam(lr=0.00001)\n",
    "model.compile(optimizer=opt,\n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=train_generator, steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                validation_data=val_generator, validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "\n",
    "# for layer in model.layers[:10]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[10:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# opt = SGD(lr=10e-5)\n",
    "# model.compile(optimizer=opt,\n",
    "#               loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit_generator(generator=train_generator, steps_per_epoch=batches.samples//batch_size, nb_epoch=1,\n",
    "#                 validation_data=valid_generator, validation_steps=valid_batches.samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the tensorboard, use command:\n",
    "tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                            steps=test_generator.n//test_generator.batch_size,\n",
    "                            verbose=1)\n",
    "pred_class=np.argmax(pred,axis=1) # index of largest value in each row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
