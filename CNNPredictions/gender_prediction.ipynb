{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'\n",
    "\n",
    "# When using plaidml, the libraries are imported from keras instead of tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [2,5]      # number of conv layers\n",
    "layer_sizes = [32,64,128]  # number of nodes in a layer\n",
    "dense_layers = [2]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_5pct.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21482, 10) (1131, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 100\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape = (image_reshape_size, image_reshape_size, 1)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>pic_date</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>93/nm0000093_rm433293312_1963-12-18_2009.jpg</td>\n",
       "      <td>2336</td>\n",
       "      <td>Brad Pitt</td>\n",
       "      <td>1963-12-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2.988206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>[67.73055822774081, 81.165869873289, 188.09436...</td>\n",
       "      <td>45.041308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425680</th>\n",
       "      <td>51/nm0584951_rm169062400_1986-8-29_2009.jpg</td>\n",
       "      <td>11601</td>\n",
       "      <td>Lea Michele</td>\n",
       "      <td>1986-08-29</td>\n",
       "      <td>0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>[1, 1, 452, 653]</td>\n",
       "      <td>22.344059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27752</th>\n",
       "      <td>96/nm0000196_rm4278383104_1963-5-25_2015.jpg</td>\n",
       "      <td>13908</td>\n",
       "      <td>Mike Myers</td>\n",
       "      <td>1963-05-25</td>\n",
       "      <td>1</td>\n",
       "      <td>4.893829</td>\n",
       "      <td>2.025698</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>[318.12685538350325, 423.486473844671, 632.157...</td>\n",
       "      <td>51.606809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     id         name  \\\n",
       "2390    93/nm0000093_rm433293312_1963-12-18_2009.jpg   2336    Brad Pitt   \n",
       "425680   51/nm0584951_rm169062400_1986-8-29_2009.jpg  11601  Lea Michele   \n",
       "27752   96/nm0000196_rm4278383104_1963-5-25_2015.jpg  13908   Mike Myers   \n",
       "\n",
       "              dob gender    score1    score2   pic_date  \\\n",
       "2390   1963-12-18      1  2.988206       NaN 2009-01-01   \n",
       "425680 1986-08-29      0      -inf       NaN 2009-01-01   \n",
       "27752  1963-05-25      1  4.893829  2.025698 2015-01-01   \n",
       "\n",
       "                                                   region        age  \n",
       "2390    [67.73055822774081, 81.165869873289, 188.09436...  45.041308  \n",
       "425680                                   [1, 1, 452, 653]  22.344059  \n",
       "27752   [318.12685538350325, 423.486473844671, 632.157...  51.606809  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19334 validated image filenames belonging to 2 classes.\n",
      "Found 2148 validated image filenames belonging to 2 classes.\n",
      "Found 1131 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                            directory=input_image_root_dir, \n",
    "                                            x_col=\"path\", y_col=None, \n",
    "                                            class_mode=None, \n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender-2-conv-32-node-2-dens-1552891559\n",
      "Epoch 1/6\n",
      "604/604 [==============================] - 162s 268ms/step - loss: 0.6495 - acc: 0.6249 - val_loss: 0.6182 - val_acc: 0.6866\n",
      "Epoch 2/6\n",
      "604/604 [==============================] - 159s 264ms/step - loss: 0.5955 - acc: 0.6929 - val_loss: 0.6053 - val_acc: 0.6829\n",
      "Epoch 3/6\n",
      "604/604 [==============================] - 159s 263ms/step - loss: 0.5656 - acc: 0.7173 - val_loss: 0.5962 - val_acc: 0.7013\n",
      "Epoch 4/6\n",
      "604/604 [==============================] - 164s 272ms/step - loss: 0.5381 - acc: 0.7342 - val_loss: 0.5890 - val_acc: 0.7051\n",
      "Epoch 5/6\n",
      "604/604 [==============================] - 152s 252ms/step - loss: 0.5113 - acc: 0.7521 - val_loss: 0.6176 - val_acc: 0.7004\n",
      "Epoch 6/6\n",
      "604/604 [==============================] - 155s 257ms/step - loss: 0.4813 - acc: 0.7660 - val_loss: 0.6180 - val_acc: 0.6777\n",
      "gender-5-conv-32-node-2-dens-1552892511\n",
      "Epoch 1/6\n",
      "604/604 [==============================] - 159s 263ms/step - loss: 0.6638 - acc: 0.6038 - val_loss: 0.6459 - val_acc: 0.6437\n",
      "Epoch 2/6\n",
      "604/604 [==============================] - 157s 260ms/step - loss: 0.6216 - acc: 0.6675 - val_loss: 0.6181 - val_acc: 0.6763\n",
      "Epoch 3/6\n",
      "604/604 [==============================] - 157s 260ms/step - loss: 0.5859 - acc: 0.7037 - val_loss: 0.5946 - val_acc: 0.7009\n",
      "Epoch 4/6\n",
      "604/604 [==============================] - 158s 262ms/step - loss: 0.5617 - acc: 0.7235 - val_loss: 0.5836 - val_acc: 0.7023\n",
      "Epoch 5/6\n",
      "604/604 [==============================] - 157s 260ms/step - loss: 0.5478 - acc: 0.7370 - val_loss: 0.5691 - val_acc: 0.7164\n",
      "Epoch 6/6\n",
      "604/604 [==============================] - 156s 259ms/step - loss: 0.5314 - acc: 0.7485 - val_loss: 0.5821 - val_acc: 0.7188\n",
      "gender-2-conv-64-node-2-dens-1552893456\n",
      "Epoch 1/6\n",
      "604/604 [==============================] - 326s 539ms/step - loss: 0.6500 - acc: 0.6242 - val_loss: 0.6353 - val_acc: 0.6612\n",
      "Epoch 2/6\n",
      "604/604 [==============================] - 323s 535ms/step - loss: 0.5890 - acc: 0.6955 - val_loss: 0.5984 - val_acc: 0.6881\n",
      "Epoch 3/6\n",
      "604/604 [==============================] - 320s 530ms/step - loss: 0.5502 - acc: 0.7238 - val_loss: 0.5957 - val_acc: 0.6980\n",
      "Epoch 4/6\n",
      "604/604 [==============================] - 322s 533ms/step - loss: 0.5007 - acc: 0.7593 - val_loss: 0.6304 - val_acc: 0.6919\n",
      "Epoch 5/6\n",
      "604/604 [==============================] - 321s 531ms/step - loss: 0.4155 - acc: 0.8070 - val_loss: 0.7352 - val_acc: 0.6777\n",
      "Epoch 6/6\n",
      "604/604 [==============================] - 322s 533ms/step - loss: 0.3103 - acc: 0.8673 - val_loss: 0.8086 - val_acc: 0.6645\n",
      "gender-5-conv-64-node-2-dens-1552895392\n",
      "Epoch 1/6\n",
      "604/604 [==============================] - 347s 574ms/step - loss: 0.6714 - acc: 0.5923 - val_loss: 0.6574 - val_acc: 0.6314\n",
      "Epoch 2/6\n",
      "604/604 [==============================] - 343s 567ms/step - loss: 0.6307 - acc: 0.6574 - val_loss: 0.6094 - val_acc: 0.6777\n",
      "Epoch 3/6\n",
      "604/604 [==============================] - 344s 569ms/step - loss: 0.5905 - acc: 0.6977 - val_loss: 0.5976 - val_acc: 0.6938\n",
      "Epoch 4/6\n",
      "604/604 [==============================] - 344s 570ms/step - loss: 0.5642 - acc: 0.7202 - val_loss: 0.5682 - val_acc: 0.7212\n",
      "Epoch 5/6\n",
      "604/604 [==============================] - 345s 571ms/step - loss: 0.5450 - acc: 0.7377 - val_loss: 0.6187 - val_acc: 0.6801\n",
      "Epoch 6/6\n",
      "604/604 [==============================] - 347s 575ms/step - loss: 0.5325 - acc: 0.7445 - val_loss: 0.5821 - val_acc: 0.7278\n",
      "gender-2-conv-128-node-2-dens-1552897463\n",
      "Epoch 1/6\n",
      "604/604 [==============================] - 858s 1s/step - loss: 0.6425 - acc: 0.6382 - val_loss: 0.6179 - val_acc: 0.6697\n",
      "Epoch 2/6\n",
      "604/604 [==============================] - 854s 1s/step - loss: 0.5839 - acc: 0.7015 - val_loss: 0.6281 - val_acc: 0.6725\n",
      "Epoch 3/6\n",
      "604/604 [==============================] - 853s 1s/step - loss: 0.5417 - acc: 0.7284 - val_loss: 0.6213 - val_acc: 0.6843\n",
      "Epoch 4/6\n",
      "604/604 [==============================] - 855s 1s/step - loss: 0.4596 - acc: 0.7819 - val_loss: 0.7857 - val_acc: 0.6938\n",
      "Epoch 5/6\n",
      "604/604 [==============================] - 853s 1s/step - loss: 0.3138 - acc: 0.8670 - val_loss: 0.9313 - val_acc: 0.6659\n",
      "Epoch 6/6\n",
      "604/604 [==============================] - 854s 1s/step - loss: 0.1738 - acc: 0.9380 - val_loss: 1.1507 - val_acc: 0.6545\n",
      "gender-5-conv-128-node-2-dens-1552902594\n",
      "Epoch 1/6\n",
      "604/604 [==============================] - 912s 2s/step - loss: 0.6798 - acc: 0.5811 - val_loss: 0.6832 - val_acc: 0.5572\n",
      "Epoch 2/6\n",
      "604/604 [==============================] - 910s 2s/step - loss: 0.6648 - acc: 0.6028 - val_loss: 0.6449 - val_acc: 0.6333\n",
      "Epoch 3/6\n",
      "604/604 [==============================] - 910s 2s/step - loss: 0.6068 - acc: 0.6850 - val_loss: 0.6135 - val_acc: 0.6720\n",
      "Epoch 4/6\n",
      "604/604 [==============================] - 911s 2s/step - loss: 0.5728 - acc: 0.7161 - val_loss: 0.5736 - val_acc: 0.7188\n",
      "Epoch 5/6\n",
      "604/604 [==============================] - 911s 2s/step - loss: 0.5574 - acc: 0.7303 - val_loss: 0.5606 - val_acc: 0.7216\n",
      "Epoch 6/6\n",
      "604/604 [==============================] - 912s 2s/step - loss: 0.5452 - acc: 0.7396 - val_loss: 0.5715 - val_acc: 0.7202\n"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'gender-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            callbacks = [tensorboard]\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=inputShape))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                                callbacks = callbacks,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                                epochs=6,\n",
    "                                use_multiprocessing=False,\n",
    "                                workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the tensorboard, use command:\n",
    "tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                            steps=test_generator.n//test_generator.batch_size,\n",
    "                            verbose=1)\n",
    "pred_class=np.argmax(pred,axis=1) # index of largest value in each row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
