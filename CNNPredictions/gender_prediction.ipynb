{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "import pickle\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [5]      # number of conv layers\n",
    "layer_sizes = [32]     # number of nodes in a layer\n",
    "dense_layers = [2]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_all.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196464, 10) (10340, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 100\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "batch_size = 64\n",
    "inputShape = (image_reshape_size, image_reshape_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>pic_date</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162143</th>\n",
       "      <td>58/nm0005158_rm1436916480_1970-11-20_2003.jpg</td>\n",
       "      <td>16965</td>\n",
       "      <td>Sabrina Lloyd</td>\n",
       "      <td>1970-11-20</td>\n",
       "      <td>0</td>\n",
       "      <td>4.224586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>[107.93942350923744, 54.230711754618724, 187.9...</td>\n",
       "      <td>32.115649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129828</th>\n",
       "      <td>07/nm0001807_rm1897044736_1933-12-19_2007.jpg</td>\n",
       "      <td>3752</td>\n",
       "      <td>Cicely Tyson</td>\n",
       "      <td>1933-12-19</td>\n",
       "      <td>0</td>\n",
       "      <td>3.434887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>[78.75376318187809, 59.19832238640856, 166.221...</td>\n",
       "      <td>73.036407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389973</th>\n",
       "      <td>79/nm0272479_rm1974701056_1975-10-22_2009.jpg</td>\n",
       "      <td>9031</td>\n",
       "      <td>Jesse Tyler Ferguson</td>\n",
       "      <td>1975-10-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>[205.814, 123.83, 266.448, 184.464]</td>\n",
       "      <td>33.197122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path     id  \\\n",
       "162143  58/nm0005158_rm1436916480_1970-11-20_2003.jpg  16965   \n",
       "129828  07/nm0001807_rm1897044736_1933-12-19_2007.jpg   3752   \n",
       "389973  79/nm0272479_rm1974701056_1975-10-22_2009.jpg   9031   \n",
       "\n",
       "                        name        dob gender    score1  score2   pic_date  \\\n",
       "162143         Sabrina Lloyd 1970-11-20      0  4.224586     NaN 2003-01-01   \n",
       "129828          Cicely Tyson 1933-12-19      0  3.434887     NaN 2007-01-01   \n",
       "389973  Jesse Tyler Ferguson 1975-10-22      1  0.899851     NaN 2009-01-01   \n",
       "\n",
       "                                                   region        age  \n",
       "162143  [107.93942350923744, 54.230711754618724, 187.9...  32.115649  \n",
       "129828  [78.75376318187809, 59.19832238640856, 166.221...  73.036407  \n",
       "389973                [205.814, 123.83, 266.448, 184.464]  33.197122  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 176818 images belonging to 2 classes.\n",
      "Found 19646 images belonging to 2 classes.\n",
      "Found 10340 images.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                            directory=input_image_root_dir, \n",
    "                                            x_col=\"path\", y_col=None, \n",
    "                                            class_mode=None, \n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BN-5-conv-32-node-2-dens-1554757735\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 407 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 629 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 670 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 705 of 1652 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009/2762 [====================>.........] - ETA: 29:32 - loss: 0.3630 - acc: 0.8155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 181 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 629 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 670 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 705 of 1652 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2761/2762 [============================>.] - ETA: 2s - loss: 0.3637 - acc: 0.8156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 183 of 259 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2762/2762 [==============================] - 6683s 2s/step - loss: 0.3638 - acc: 0.8156 - val_loss: 0.3722 - val_acc: 0.8103\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 206 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 629 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 670 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 705 of 1652 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2762 [====================>.........] - ETA: 29:46 - loss: 0.3608 - acc: 0.8175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 407 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 635 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 683 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 706 of 1652 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2761/2762 [============================>.] - ETA: 2s - loss: 0.3599 - acc: 0.8181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 195 of 258 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2762/2762 [==============================] - 6716s 2s/step - loss: 0.3599 - acc: 0.8181 - val_loss: 0.3781 - val_acc: 0.8075\n",
      "Epoch 3/5\n",
      "2762/2762 [==============================] - 6777s 2s/step - loss: 0.3605 - acc: 0.8179 - val_loss: 0.3726 - val_acc: 0.8112\n",
      "Epoch 4/5\n",
      "2762/2762 [==============================] - 6650s 2s/step - loss: 0.3578 - acc: 0.8197 - val_loss: 0.3778 - val_acc: 0.8097\n",
      "Epoch 5/5\n",
      "2111/2762 [=====================>........] - ETA: 25:40 - loss: 0.3587 - acc: 0.8184"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'BN-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            checkpoint = ModelCheckpoint('weights/{}'.format(NAME), monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "            callbacks = [tensorboard, checkpoint]\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\", input_shape=inputShape))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                layer_size *= 2\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.5))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            layer_size *= 4 # to get the dense layer to be 8X of last output size\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Dropout(0.7))\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            # Optional for resuming, load weights\n",
    "            model.load_weights('weights/BN-5-conv-32-node-2-dens-1554706050')\n",
    "\n",
    "            opt = Adam(lr=0.0002)\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "            \n",
    "            model.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                                callbacks = callbacks,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                                epochs=5,\n",
    "                                use_multiprocessing=False,\n",
    "                                workers=4)\n",
    "            \n",
    "            filepath = NAME + '.h5'\n",
    "            model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN-final-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model, resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = 'BN-5-conv-32-node-2-dens-1553895953-3.h5'\n",
    "model = load_model(inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveAs = 'BN-5-conv-32-node-2-dens-1553895953-4Lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "NAME = saveAs\n",
    "print(NAME) \n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "callbacks = [tensorboard]\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                    epochs=5,\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=8)\n",
    "\n",
    "filepath = NAME + '.h5'\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('CNN-final-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10340/10340 [==============================] - 592s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                            steps=test_generator.n//test_generator.batch_size,\n",
    "                            verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = df_test.gender.astype(int)\n",
    "y_pred = [1 if x>=0.5 else 0 for x in pred]\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3474, 1651],\n",
       "       [ 387, 4828]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm[0][0]\n",
    "TP = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6778536585365854"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7451767248032104"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.47545219638243"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8029013539651838"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TP+TN)/(TN+TP+FN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Live Demo with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('CNN-final-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    \n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (100, 100))\n",
    "    return new_array.reshape(-1, 100, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(prepare('picture.jpg'))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Live Demo with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
