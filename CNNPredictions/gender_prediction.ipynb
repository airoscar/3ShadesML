{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "import pickle\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [5]      # number of conv layers\n",
    "layer_sizes = [32]     # number of nodes in a layer\n",
    "dense_layers = [2]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_all.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429648, 10) (22613, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 120\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "batch_size = 32\n",
    "inputShape = (image_reshape_size, image_reshape_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22613 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                            directory=input_image_root_dir, \n",
    "                                            x_col=\"path\", y_col=None, \n",
    "                                            class_mode=None, \n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for data generator\n",
    "params = {'dim': inputShape,\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'BN-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            callbacks = [tensorboard]\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\", input_shape=inputShape))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                layer_size *= 2\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.25))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            layer_size *= 4 # to get the dense layer to be 8X of last output size\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Dropout(0.5))\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            opt = Adam(lr=0.001)\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                                callbacks = callbacks,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                                epochs=10,\n",
    "                                use_multiprocessing=False,\n",
    "                                workers=4)\n",
    "            \n",
    "            filepath = NAME + '.h5'\n",
    "            model.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model, resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_amd_radeon_rx_vega_56.0\"\n"
     ]
    }
   ],
   "source": [
    "inputFile = 'BN-5-conv-32-node-2-dens-1553895953.h5'\n",
    "model = load_model(inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveAs = 'BN-5-conv-32-node-2-dens-1553895953-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BN-5-conv-32-node-2-dens-1553895953-4\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/potatorun/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
      "INFO:plaidml:Analyzing Ops: 88 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 517 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 670 of 1652 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 951 of 1652 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12082/12083 [============================>.] - ETA: 0s - loss: 0.4750 - acc: 0.7747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 92 of 259 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12083/12083 [==============================] - 3654s 302ms/step - loss: 0.4750 - acc: 0.7747 - val_loss: 0.5472 - val_acc: 0.7412\n",
      "Epoch 2/5\n",
      "12083/12083 [==============================] - 3885s 322ms/step - loss: 0.4929 - acc: 0.7678 - val_loss: 0.5427 - val_acc: 0.7512\n",
      "Epoch 3/5\n",
      " 7640/12083 [=================>............] - ETA: 25:07 - loss: 0.4922 - acc: 0.7711"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "NAME = saveAs\n",
    "print(NAME) \n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "callbacks = [tensorboard]\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                    epochs=5,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4)\n",
    "\n",
    "filepath = NAME + '.h5'\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 142 of 228 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22613/22613 [==============================] - 780s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                            steps=test_generator.n//test_generator.batch_size,\n",
    "                            verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = df_test.gender.astype(int)\n",
    "y_pred = [1 if x>=0.5 else 0 for x in pred]\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6128,  3257],\n",
       "       [ 2244, 10984]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm[0][0]\n",
    "TP = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6529568460309003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771294150691665"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.894830659536542"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.756732852783797"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TP+TN)/(TN+TP+FN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import itertools\n",
    "import math\n",
    "def plotConfusionMatrix(confusionMatrix, classes, title='Confusion matrix', \n",
    "                        cmap=None, figsize=None, ylabel='True classes', xlabel='Predicted classes',\n",
    "                        save=False, filepath=\"confusion_matrix.png\"):\n",
    "\n",
    "    if cmap is None: cmap=pyplot.cm.Reds\n",
    "    if figsize is None: figsize=[7,5]\n",
    "\n",
    "    if not ((confusionMatrix.sum(axis=1)<=1).all()==True):\n",
    "        # a test dataset of only 1 datapoint will fool the above condition.\n",
    "        confusionMatrix=normalizeConfusionMatrix(confusionMatrix)\n",
    "\n",
    "    confusionMatrix=confusionMatrix*100\n",
    "\n",
    "    fig=pyplot.figure(figsize=figsize)\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "\n",
    "    axImg=ax.imshow(confusionMatrix, cmap=cmap)\n",
    "    fig.colorbar(axImg, fraction=0.046, pad=0.04)\n",
    "\n",
    "    ax.set_title(title)\n",
    "\n",
    "    tick_positions = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(classes, rotation=45)\n",
    "    ax.set_yticks(tick_positions)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    threshold = (np.nanmax(confusionMatrix)+np.nanmin(confusionMatrix)) / 1.5\n",
    "    r=confusionMatrix.shape[0]\n",
    "    c=confusionMatrix.shape[1]\n",
    "\n",
    "    for i, j in itertools.product(range(r), range(c)):\n",
    "        ax.text(j, i, format(confusionMatrix[i, j], fmt)+\"%\",\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if (confusionMatrix[i, j] > threshold) else \"black\")\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save is True: fig.savefig(filepath)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return None\n",
    "\n",
    "def normalizeConfusionMatrix(confusionMatrix):\n",
    "    normConfusionMatrix = confusionMatrix.astype('float') / confusionMatrix.sum(axis=1)[:, np.newaxis]\n",
    "    return normConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/potatorun/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:457: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotConfusionMatrix(cm, classes=[\"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('BN-5-conv-32-node-2-dens-1553895953.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    IMG_SIZE = image_reshape_size\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(prepare('picture.jpg'))\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
