{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [5]      # number of conv layers\n",
    "layer_sizes = [32]     # number of nodes in a layer\n",
    "dense_layers = [2]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_all.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42965, 10) (2261, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 120\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "batch_size = 64\n",
    "inputShape = (image_reshape_size, image_reshape_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>pic_date</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120097</th>\n",
       "      <td>12/nm0001612_rm2398793472_1969-8-19_2012.jpg</td>\n",
       "      <td>13149</td>\n",
       "      <td>Matthew Perry</td>\n",
       "      <td>1969-08-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>[397.6, 52.0, 454.4, 108.8]</td>\n",
       "      <td>42.369111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110887</th>\n",
       "      <td>35/nm0001435_rm3857046784_1963-7-30_1994.jpg</td>\n",
       "      <td>11966</td>\n",
       "      <td>Lisa Kudrow</td>\n",
       "      <td>1963-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>[1132.544, 313.344, 1277.952, 458.752]</td>\n",
       "      <td>30.426361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59955</th>\n",
       "      <td>59/nm0000459_rm3615721728_1960-8-16_2008.jpg</td>\n",
       "      <td>18968</td>\n",
       "      <td>Timothy Hutton</td>\n",
       "      <td>1960-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.119279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>[282.03335656952333, 55.67480128185821, 342.96...</td>\n",
       "      <td>47.376743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     id            name  \\\n",
       "120097  12/nm0001612_rm2398793472_1969-8-19_2012.jpg  13149   Matthew Perry   \n",
       "110887  35/nm0001435_rm3857046784_1963-7-30_1994.jpg  11966     Lisa Kudrow   \n",
       "59955   59/nm0000459_rm3615721728_1960-8-16_2008.jpg  18968  Timothy Hutton   \n",
       "\n",
       "              dob gender    score1  score2   pic_date  \\\n",
       "120097 1969-08-19      1  0.799562     NaN 2012-01-01   \n",
       "110887 1963-07-30      0  0.774393     NaN 1994-01-01   \n",
       "59955  1960-08-16      1  2.119279     NaN 2008-01-01   \n",
       "\n",
       "                                                   region        age  \n",
       "120097                        [397.6, 52.0, 454.4, 108.8]  42.369111  \n",
       "110887             [1132.544, 313.344, 1277.952, 458.752]  30.426361  \n",
       "59955   [282.03335656952333, 55.67480128185821, 342.96...  47.376743  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38669 images belonging to 2 classes.\n",
      "Found 4296 images belonging to 2 classes.\n",
      "Found 2261 images.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                            directory=input_image_root_dir, \n",
    "                                            x_col=\"path\", y_col=None, \n",
    "                                            class_mode=None, \n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BN-5-conv-32-node-2-dens-1553790061\n",
      "WARNING:tensorflow:From C:\\Users\\oscar.chen1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\oscar.chen1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\oscar.chen1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "1208/1208 [==============================] - 1238s 1s/step - loss: 0.7853 - acc: 0.5874 - val_loss: 0.6441 - val_acc: 0.6413\n",
      "Epoch 2/30\n",
      "1208/1208 [==============================] - 1232s 1s/step - loss: 0.6858 - acc: 0.6276 - val_loss: 0.6666 - val_acc: 0.6348\n",
      "Epoch 3/30\n",
      "1208/1208 [==============================] - 1208s 1s/step - loss: 0.6639 - acc: 0.6618 - val_loss: 0.5909 - val_acc: 0.7000\n",
      "Epoch 4/30\n",
      "1208/1208 [==============================] - 1209s 1s/step - loss: 0.6468 - acc: 0.6792 - val_loss: 0.6062 - val_acc: 0.6935\n",
      "Epoch 5/30\n",
      "1208/1208 [==============================] - 1224s 1s/step - loss: 0.6352 - acc: 0.6893 - val_loss: 0.6245 - val_acc: 0.6639\n",
      "Epoch 6/30\n",
      "1208/1208 [==============================] - 1208s 1000ms/step - loss: 0.6249 - acc: 0.7024 - val_loss: 0.6584 - val_acc: 0.6947\n",
      "Epoch 7/30\n",
      "1208/1208 [==============================] - 1207s 999ms/step - loss: 0.6264 - acc: 0.7069 - val_loss: 0.7118 - val_acc: 0.6295\n",
      "Epoch 8/30\n",
      "1208/1208 [==============================] - 1210s 1s/step - loss: 0.6128 - acc: 0.7095 - val_loss: 0.6926 - val_acc: 0.7066\n",
      "Epoch 9/30\n",
      "1208/1208 [==============================] - 1242s 1s/step - loss: 0.5940 - acc: 0.7207 - val_loss: 0.5639 - val_acc: 0.7364\n",
      "Epoch 10/30\n",
      "1208/1208 [==============================] - 1224s 1s/step - loss: 0.5959 - acc: 0.7233 - val_loss: 0.6295 - val_acc: 0.6550\n",
      "Epoch 11/30\n",
      "1208/1208 [==============================] - 1208s 1s/step - loss: 0.5823 - acc: 0.7295 - val_loss: 0.5751 - val_acc: 0.7298\n",
      "Epoch 12/30\n",
      "1208/1208 [==============================] - 1220s 1s/step - loss: 0.5799 - acc: 0.7333 - val_loss: 0.5638 - val_acc: 0.7305\n",
      "Epoch 13/30\n",
      "1208/1208 [==============================] - 1208s 1000ms/step - loss: 0.6025 - acc: 0.7235 - val_loss: 0.5784 - val_acc: 0.7444\n",
      "Epoch 14/30\n",
      "1208/1208 [==============================] - 1206s 998ms/step - loss: 0.5724 - acc: 0.7359 - val_loss: 0.5474 - val_acc: 0.7451\n",
      "Epoch 15/30\n",
      "1208/1208 [==============================] - 1206s 998ms/step - loss: 0.5603 - acc: 0.7428 - val_loss: 0.5605 - val_acc: 0.7399\n",
      "Epoch 16/30\n",
      "1208/1208 [==============================] - 1208s 1s/step - loss: 0.5714 - acc: 0.7339 - val_loss: 0.5546 - val_acc: 0.7383\n",
      "Epoch 17/30\n",
      "1208/1208 [==============================] - 1216s 1s/step - loss: 0.5581 - acc: 0.7437 - val_loss: 0.5817 - val_acc: 0.7090\n",
      "Epoch 18/30\n",
      "1208/1208 [==============================] - 1209s 1s/step - loss: 0.5612 - acc: 0.7415 - val_loss: 0.5473 - val_acc: 0.7394\n",
      "Epoch 19/30\n",
      "1208/1208 [==============================] - 1222s 1s/step - loss: 0.5476 - acc: 0.7499 - val_loss: 0.5428 - val_acc: 0.7448\n",
      "Epoch 20/30\n",
      "1208/1208 [==============================] - 1210s 1s/step - loss: 0.5437 - acc: 0.7494 - val_loss: 0.5496 - val_acc: 0.7413\n",
      "Epoch 21/30\n",
      "1208/1208 [==============================] - 1210s 1s/step - loss: 0.5524 - acc: 0.7468 - val_loss: 0.6125 - val_acc: 0.7404\n",
      "Epoch 22/30\n",
      "1208/1208 [==============================] - 1211s 1s/step - loss: 0.5402 - acc: 0.7541 - val_loss: 0.5400 - val_acc: 0.7519\n",
      "Epoch 23/30\n",
      "1208/1208 [==============================] - 1209s 1s/step - loss: 0.5310 - acc: 0.7601 - val_loss: 0.6226 - val_acc: 0.6954\n",
      "Epoch 24/30\n",
      "1208/1208 [==============================] - 1210s 1s/step - loss: 0.5384 - acc: 0.7520 - val_loss: 0.5495 - val_acc: 0.7425\n",
      "Epoch 25/30\n",
      "1208/1208 [==============================] - 1218s 1s/step - loss: 0.5191 - acc: 0.7643 - val_loss: 0.5585 - val_acc: 0.7509\n",
      "Epoch 26/30\n",
      "1208/1208 [==============================] - 1227s 1s/step - loss: 0.5084 - acc: 0.7668 - val_loss: 0.5845 - val_acc: 0.7326\n",
      "Epoch 27/30\n",
      "1208/1208 [==============================] - 1218s 1s/step - loss: 0.5113 - acc: 0.7651 - val_loss: 0.5444 - val_acc: 0.7528\n",
      "Epoch 28/30\n",
      "1208/1208 [==============================] - 1214s 1s/step - loss: 0.4915 - acc: 0.7749 - val_loss: 0.5612 - val_acc: 0.7364\n",
      "Epoch 29/30\n",
      "1208/1208 [==============================] - 1216s 1s/step - loss: 0.4705 - acc: 0.7865 - val_loss: 0.5590 - val_acc: 0.7488\n",
      "Epoch 30/30\n",
      "1208/1208 [==============================] - 1214s 1s/step - loss: 0.4540 - acc: 0.7947 - val_loss: 0.6074 - val_acc: 0.7371\n"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'BN-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            callbacks = [tensorboard]\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\", input_shape=inputShape))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                layer_size *= 2\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.25))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            layer_size *= 4 # to get the dense layer to be 8X of last output size\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Dropout(0.5))\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            opt = Adam(lr=0.001)\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                                callbacks = callbacks,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                                epochs=15,\n",
    "                                use_multiprocessing=False,\n",
    "                                workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 66s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                            steps=test_generator.n//test_generator.batch_size,\n",
    "                            verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = df_test.gender.astype(int)\n",
    "y_pred = [1 if x>=0.5 else 0 for x in pred]\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[588, 331],\n",
       "       [343, 999]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm[0][0]\n",
    "TP = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6398258977149075"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7511278195488722"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.912536443148688"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7019018133569217"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(TP+TN)/(TN+TP+FN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
