{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'\n",
    "\n",
    "# When using plaidml, the libraries are imported from keras instead of tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [5]      # number of conv layers\n",
    "layer_sizes = [32]  # number of nodes in a layer\n",
    "dense_layers = [3]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_5pct.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21482, 10) (1131, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 120\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "batch_size = 64\n",
    "inputShape = (image_reshape_size, image_reshape_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>pic_date</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>93/nm0000093_rm433293312_1963-12-18_2009.jpg</td>\n",
       "      <td>2336</td>\n",
       "      <td>Brad Pitt</td>\n",
       "      <td>1963-12-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2.988206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>[67.73055822774081, 81.165869873289, 188.09436...</td>\n",
       "      <td>45.041308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425680</th>\n",
       "      <td>51/nm0584951_rm169062400_1986-8-29_2009.jpg</td>\n",
       "      <td>11601</td>\n",
       "      <td>Lea Michele</td>\n",
       "      <td>1986-08-29</td>\n",
       "      <td>0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>[1, 1, 452, 653]</td>\n",
       "      <td>22.344059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27752</th>\n",
       "      <td>96/nm0000196_rm4278383104_1963-5-25_2015.jpg</td>\n",
       "      <td>13908</td>\n",
       "      <td>Mike Myers</td>\n",
       "      <td>1963-05-25</td>\n",
       "      <td>1</td>\n",
       "      <td>4.893829</td>\n",
       "      <td>2.025698</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>[318.12685538350325, 423.486473844671, 632.157...</td>\n",
       "      <td>51.606809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     id         name  \\\n",
       "2390    93/nm0000093_rm433293312_1963-12-18_2009.jpg   2336    Brad Pitt   \n",
       "425680   51/nm0584951_rm169062400_1986-8-29_2009.jpg  11601  Lea Michele   \n",
       "27752   96/nm0000196_rm4278383104_1963-5-25_2015.jpg  13908   Mike Myers   \n",
       "\n",
       "              dob gender    score1    score2   pic_date  \\\n",
       "2390   1963-12-18      1  2.988206       NaN 2009-01-01   \n",
       "425680 1986-08-29      0      -inf       NaN 2009-01-01   \n",
       "27752  1963-05-25      1  4.893829  2.025698 2015-01-01   \n",
       "\n",
       "                                                   region        age  \n",
       "2390    [67.73055822774081, 81.165869873289, 188.09436...  45.041308  \n",
       "425680                                   [1, 1, 452, 653]  22.344059  \n",
       "27752   [318.12685538350325, 423.486473844671, 632.157...  51.606809  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19334 images belonging to 2 classes.\n",
      "Found 2148 images belonging to 2 classes.\n",
      "Found 1131 images.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                            directory=input_image_root_dir, \n",
    "                                            x_col=\"path\", y_col=None, \n",
    "                                            class_mode=None, \n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BN-5-conv-32-node-3-dens-1553703610\n",
      "Epoch 1/10\n",
      " 29/604 [>.............................] - ETA: 12:34 - loss: 2.0081 - acc: 0.5054"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'BN-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            callbacks = [tensorboard]\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\", input_shape=inputShape))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                layer_size *= 2\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.25))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            layer_size *= 4 # to get the dense layer to be 8X of last output size\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Dropout(0.5))\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            opt = Adam(lr=0.001)\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                                callbacks = callbacks,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                                epochs=10,\n",
    "                                use_multiprocessing=False,\n",
    "                                workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Lambda, Conv2D\n",
    "from keras.layers import GlobalAveragePooling2D, Input, Dropout\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import numpy as np\n",
    "import urllib\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "model_path = 'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "target_size=(224, 224)\n",
    "batch_size=32\n",
    "\n",
    "def preprocess_image(im):\n",
    "    vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "    #im = cv2.resize(cv2.imread(path), (224, 224)).astype(np.float32)\n",
    "    im = (im - vgg_mean)\n",
    "    return im[:, ::-1] # RGB to BGR\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(preprocess_image, input_shape=inputShape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=inputShape, activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "model.load_weights(model_path)\n",
    "\n",
    "\n",
    "x = Dense(1, activation='softmax')(model.layers[-2].output)\n",
    "model = Model(model.input, x)\n",
    "\n",
    "for layer in model.layers: \n",
    "    layer.trainable=False\n",
    "\n",
    "opt = Adam(lr=0.00001)\n",
    "model.compile(optimizer=opt,\n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=train_generator, steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                validation_data=val_generator, validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "\n",
    "# for layer in model.layers[:10]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[10:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# opt = SGD(lr=10e-5)\n",
    "# model.compile(optimizer=opt,\n",
    "#               loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit_generator(generator=train_generator, steps_per_epoch=batches.samples//batch_size, nb_epoch=1,\n",
    "#                 validation_data=valid_generator, validation_steps=valid_batches.samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the tensorboard, use command:\n",
    "tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                            steps=test_generator.n//test_generator.batch_size,\n",
    "                            verbose=1)\n",
    "pred_class=np.argmax(pred,axis=1) # index of largest value in each row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
