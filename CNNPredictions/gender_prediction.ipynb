{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'\n",
    "\n",
    "# When using plaidml, the libraries are imported from keras instead of tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [4,5]      # number of conv layers\n",
    "layer_sizes = [32]  # number of nodes in a layer\n",
    "dense_layers = [2]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_10pct.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42965, 10) (2261, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 120\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "batch_size = 64\n",
    "inputShape = (image_reshape_size, image_reshape_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>pic_date</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120097</th>\n",
       "      <td>12/nm0001612_rm2398793472_1969-8-19_2012.jpg</td>\n",
       "      <td>13149</td>\n",
       "      <td>Matthew Perry</td>\n",
       "      <td>1969-08-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>[397.6, 52.0, 454.4, 108.8]</td>\n",
       "      <td>42.369111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110887</th>\n",
       "      <td>35/nm0001435_rm3857046784_1963-7-30_1994.jpg</td>\n",
       "      <td>11966</td>\n",
       "      <td>Lisa Kudrow</td>\n",
       "      <td>1963-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>[1132.544, 313.344, 1277.952, 458.752]</td>\n",
       "      <td>30.426361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59955</th>\n",
       "      <td>59/nm0000459_rm3615721728_1960-8-16_2008.jpg</td>\n",
       "      <td>18968</td>\n",
       "      <td>Timothy Hutton</td>\n",
       "      <td>1960-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.119279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>[282.03335656952333, 55.67480128185821, 342.96...</td>\n",
       "      <td>47.376743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     id            name  \\\n",
       "120097  12/nm0001612_rm2398793472_1969-8-19_2012.jpg  13149   Matthew Perry   \n",
       "110887  35/nm0001435_rm3857046784_1963-7-30_1994.jpg  11966     Lisa Kudrow   \n",
       "59955   59/nm0000459_rm3615721728_1960-8-16_2008.jpg  18968  Timothy Hutton   \n",
       "\n",
       "              dob gender    score1  score2   pic_date  \\\n",
       "120097 1969-08-19      1  0.799562     NaN 2012-01-01   \n",
       "110887 1963-07-30      0  0.774393     NaN 1994-01-01   \n",
       "59955  1960-08-16      1  2.119279     NaN 2008-01-01   \n",
       "\n",
       "                                                   region        age  \n",
       "120097                        [397.6, 52.0, 454.4, 108.8]  42.369111  \n",
       "110887             [1132.544, 313.344, 1277.952, 458.752]  30.426361  \n",
       "59955   [282.03335656952333, 55.67480128185821, 342.96...  47.376743  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38669 images belonging to 2 classes.\n",
      "Found 4296 images belonging to 2 classes.\n",
      "Found 2261 images.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"training\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                            directory=input_image_root_dir,\n",
    "                                            x_col=\"path\", y_col=\"gender\",\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode=\"binary\",\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=32,\n",
    "                                            seed=1,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                            directory=input_image_root_dir, \n",
    "                                            x_col=\"path\", y_col=None, \n",
    "                                            class_mode=None, \n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size=(image_reshape_size,image_reshape_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BN-4-conv-32-node-2-dens-1553736475\n",
      "Epoch 1/30\n",
      " 175/1208 [===>..........................] - ETA: 14:18 - loss: 0.9977 - acc: 0.5543"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'BN-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            callbacks = [tensorboard]\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\", input_shape=inputShape))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                layer_size *= 2\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(layer_size, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(Dropout(0.25))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            layer_size *= 4 # to get the dense layer to be 8X of last output size\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Dropout(0.5))\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            opt = Adam(lr=0.001)\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "                                callbacks = callbacks,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=(val_generator.n // val_generator.batch_size),\n",
    "                                epochs=30,\n",
    "                                use_multiprocessing=False,\n",
    "                                workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Lambda, Conv2D\n",
    "from keras.layers import GlobalAveragePooling2D, Input, Dropout\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import numpy as np\n",
    "import urllib\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "model_path = 'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "target_size=(224, 224)\n",
    "batch_size=32\n",
    "\n",
    "def preprocess_image(im):\n",
    "    vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "    #im = cv2.resize(cv2.imread(path), (224, 224)).astype(np.float32)\n",
    "    im = (im - vgg_mean)\n",
    "    return im[:, ::-1] # RGB to BGR\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(preprocess_image, input_shape=inputShape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=inputShape, activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "model.load_weights(model_path)\n",
    "\n",
    "\n",
    "x = Dense(1, activation='softmax')(model.layers[-2].output)\n",
    "model = Model(model.input, x)\n",
    "\n",
    "for layer in model.layers: \n",
    "    layer.trainable=False\n",
    "\n",
    "opt = Adam(lr=0.00001)\n",
    "model.compile(optimizer=opt,\n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=train_generator, steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                validation_data=val_generator, validation_steps=val_generator.n // val_generator.batch_size)\n",
    "\n",
    "\n",
    "# for layer in model.layers[:10]:\n",
    "#     layer.trainable = False\n",
    "# for layer in model.layers[10:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# opt = SGD(lr=10e-5)\n",
    "# model.compile(optimizer=opt,\n",
    "#               loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit_generator(generator=train_generator, steps_per_epoch=batches.samples//batch_size, nb_epoch=1,\n",
    "#                 validation_data=valid_generator, validation_steps=valid_batches.samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the tensorboard, use command:\n",
    "tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                            steps=test_generator.n//test_generator.batch_size,\n",
    "                            verbose=1)\n",
    "pred_class=np.argmax(pred,axis=1) # index of largest value in each row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
