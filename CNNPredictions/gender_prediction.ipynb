{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.utils import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If using AMD GPU, switch backend to PlaidML library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='plaidml.keras.backend'\n",
    "\n",
    "# When using plaidml, the libraries are imported from keras instead of tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [1, 2, 3]      # number of conv layers\n",
    "layer_sizes = [32, 64, 128]  # number of nodes in a layer\n",
    "dense_layers = [0, 1, 2]     # number of dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../Dataset/df_1pct.pickle', 'rb')\n",
    "df_train, df_test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Keras ImageDataGenerator uses string type data label\n",
    "df_train['gender'] = df_train.gender.astype(str)\n",
    "df_test['gender'] = df_test.gender.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4297, 10) (226, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path                object\n",
       "id                  uint16\n",
       "name                object\n",
       "dob         datetime64[ns]\n",
       "gender              object\n",
       "score1             float64\n",
       "score2             float64\n",
       "pic_date    datetime64[ns]\n",
       "region              object\n",
       "age                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a generator to feed model with images, the X would be the path to these images. y will be the gender label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshape_size = 100\n",
    "input_image_root_dir = '../Dataset/imdb_crop/' # Don't forget the ending slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = input_image_root_dir + df_train.path\n",
    "X_test = input_image_root_dir + df_test.path \n",
    "y_train = df_train.gender\n",
    "y_test = df_test.gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape = (image_reshape_size, image_reshape_size, 1)\n",
    "batch_size = 32\n",
    "num_training_samples = X_train.size\n",
    "num_validation_samples = X_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>pic_date</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351096</th>\n",
       "      <td>67/nm0755267_rm3707735808_1980-4-8_2001.jpg</td>\n",
       "      <td>10591</td>\n",
       "      <td>Katee Sackhoff</td>\n",
       "      <td>1980-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>3.704906</td>\n",
       "      <td>3.597096</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>[159.42317678741446, 51.63402111024036, 209.90...</td>\n",
       "      <td>20.734170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436852</th>\n",
       "      <td>25/nm0090225_rm1239005952_1964-10-25_2007.jpg</td>\n",
       "      <td>13481</td>\n",
       "      <td>Michael Boatman</td>\n",
       "      <td>1964-10-25</td>\n",
       "      <td>1</td>\n",
       "      <td>2.629246</td>\n",
       "      <td>1.647017</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>[80.61172611750719, 114.87418016786741, 131.33...</td>\n",
       "      <td>42.185671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115652</th>\n",
       "      <td>18/nm0001518_rm2982264064_1961-10-26_2011.jpg</td>\n",
       "      <td>5456</td>\n",
       "      <td>Dylan McDermott</td>\n",
       "      <td>1961-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>2.793912</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>[446.31, 70.47, 570.72, 194.88000000000002]</td>\n",
       "      <td>49.183761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path     id             name  \\\n",
       "351096    67/nm0755267_rm3707735808_1980-4-8_2001.jpg  10591   Katee Sackhoff   \n",
       "436852  25/nm0090225_rm1239005952_1964-10-25_2007.jpg  13481  Michael Boatman   \n",
       "115652  18/nm0001518_rm2982264064_1961-10-26_2011.jpg   5456  Dylan McDermott   \n",
       "\n",
       "              dob  gender    score1    score2   pic_date  \\\n",
       "351096 1980-04-08       0  3.704906  3.597096 2001-01-01   \n",
       "436852 1964-10-25       1  2.629246  1.647017 2007-01-01   \n",
       "115652 1961-10-26       1  2.793912  1.419481 2011-01-01   \n",
       "\n",
       "                                                   region        age  \n",
       "351096  [159.42317678741446, 51.63402111024036, 209.90...  20.734170  \n",
       "436852  [80.61172611750719, 114.87418016786741, 131.33...  42.185671  \n",
       "115652        [446.31, 70.47, 570.72, 194.88000000000002]  49.183761  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input image generator using flow_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4297 validated image filenames belonging to 2 classes.\n",
      "Found 226 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                              directory=input_image_root_dir,\n",
    "                                              x_col=\"path\", y_col=\"gender\",\n",
    "                                              class_mode=\"binary\",\n",
    "                                              color_mode=\"grayscale\",\n",
    "                                              target_size=(image_reshape_size,image_reshape_size),\n",
    "                                              batch_size=32)\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=df_test, \n",
    "                                             directory=input_image_root_dir, \n",
    "                                             x_col=\"path\", y_col=\"gender\", \n",
    "                                             class_mode=\"binary\", \n",
    "                                             color_mode=\"grayscale\",\n",
    "                                             target_size=(image_reshape_size,image_reshape_size),\n",
    "                                             batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender-1-conv-32-node-0-dens-1552855187\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 31s 229ms/step - loss: 0.6760 - acc: 0.5851 - val_loss: 0.6339 - val_acc: 0.6875\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 27s 199ms/step - loss: 0.6129 - acc: 0.6699 - val_loss: 0.6094 - val_acc: 0.6546\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 25s 187ms/step - loss: 0.5536 - acc: 0.7349 - val_loss: 0.5886 - val_acc: 0.6701\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 25s 189ms/step - loss: 0.4964 - acc: 0.7796 - val_loss: 0.5889 - val_acc: 0.6856\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 26s 197ms/step - loss: 0.4425 - acc: 0.8133 - val_loss: 0.6596 - val_acc: 0.6392\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 22s 162ms/step - loss: 0.3987 - acc: 0.8479 - val_loss: 0.6065 - val_acc: 0.6443\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 22s 161ms/step - loss: 0.3583 - acc: 0.8660 - val_loss: 0.7306 - val_acc: 0.6031\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 22s 165ms/step - loss: 0.3153 - acc: 0.8908 - val_loss: 0.6725 - val_acc: 0.6546\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 22s 163ms/step - loss: 0.2809 - acc: 0.9100 - val_loss: 0.7194 - val_acc: 0.6518\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 22s 165ms/step - loss: 0.2547 - acc: 0.9210 - val_loss: 0.6950 - val_acc: 0.6546\n",
      "gender-2-conv-32-node-0-dens-1552855431\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 38s 284ms/step - loss: 0.6728 - acc: 0.5859 - val_loss: 0.6836 - val_acc: 0.5258\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 36s 270ms/step - loss: 0.6349 - acc: 0.6440 - val_loss: 0.5943 - val_acc: 0.6856\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 35s 261ms/step - loss: 0.6140 - acc: 0.6676 - val_loss: 0.5971 - val_acc: 0.6546\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 35s 259ms/step - loss: 0.5787 - acc: 0.7126 - val_loss: 0.5957 - val_acc: 0.7113\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 35s 258ms/step - loss: 0.5457 - acc: 0.7274 - val_loss: 0.6416 - val_acc: 0.6546\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 34s 254ms/step - loss: 0.5214 - acc: 0.7390 - val_loss: 0.6153 - val_acc: 0.6920\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 33s 250ms/step - loss: 0.4805 - acc: 0.7757 - val_loss: 0.6430 - val_acc: 0.6649\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 31s 234ms/step - loss: 0.4477 - acc: 0.8022 - val_loss: 0.6937 - val_acc: 0.6443\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 32s 236ms/step - loss: 0.4158 - acc: 0.8127 - val_loss: 0.7173 - val_acc: 0.6082\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 31s 234ms/step - loss: 0.3790 - acc: 0.8299 - val_loss: 0.7510 - val_acc: 0.6495\n",
      "gender-3-conv-32-node-0-dens-1552855772\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 37s 277ms/step - loss: 0.6813 - acc: 0.5773 - val_loss: 0.6657 - val_acc: 0.5825\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 36s 267ms/step - loss: 0.6602 - acc: 0.6063 - val_loss: 0.6113 - val_acc: 0.6959\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 37s 273ms/step - loss: 0.6414 - acc: 0.6435 - val_loss: 0.6069 - val_acc: 0.7062\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 35s 263ms/step - loss: 0.6149 - acc: 0.6708 - val_loss: 0.6004 - val_acc: 0.6429\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 38s 281ms/step - loss: 0.6012 - acc: 0.6830 - val_loss: 0.5940 - val_acc: 0.7113\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 37s 273ms/step - loss: 0.5793 - acc: 0.7070 - val_loss: 0.6018 - val_acc: 0.7010\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 36s 268ms/step - loss: 0.5645 - acc: 0.7215 - val_loss: 0.6625 - val_acc: 0.6237\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 35s 264ms/step - loss: 0.5459 - acc: 0.7281 - val_loss: 0.6198 - val_acc: 0.6649\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 36s 268ms/step - loss: 0.5179 - acc: 0.7493 - val_loss: 0.6077 - val_acc: 0.7113\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 37s 273ms/step - loss: 0.4956 - acc: 0.7664 - val_loss: 0.7374 - val_acc: 0.6237\n",
      "gender-1-conv-64-node-0-dens-1552856135\n",
      "Epoch 1/10\n",
      "102/134 [=====================>........] - ETA: 8s - loss: 0.6870 - acc: 0.5816"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = 'gender-{}-conv-{}-node-{}-dens-{}'.format(conv_layer, layer_size, dense_layer, int(time.time()))  # model name with timestamp\n",
    "            print(NAME) \n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # first layer\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=inputShape))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            # sets up additional # of conv layers\n",
    "            for _ in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            # sets up # of dense layers\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "            \n",
    "            # output layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', \n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "                       \n",
    "#             train_generator = DataGenerator(X_train, y_train, batch_size)\n",
    "#             test_generator = DataGenerator(X_test, y_test, batch_size)\n",
    "\n",
    "            model.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=(train_generator.n // train_generator.batch_size),\n",
    "#                                 callbacks = tensorboard,\n",
    "                                validation_data=test_generator,\n",
    "                                validation_steps=(test_generator.n // test_generator.batch_size),\n",
    "                                epochs=10,\n",
    "                                use_multiprocessing=False,\n",
    "                                workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
